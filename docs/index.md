## Inputs

Our experimentalist considers the following inputs:

### 1. `conditions` (Already tested points)
- **Purpose**: Calculate novelty scores and identify under-covered regions
- **Why**: We need to know what has been tested to avoid redundant measurements and find gaps in knowledge

### 2. `reference_conditions` (Full candidate grid)
- **Purpose**: Defines the complete experimental space
- **Why**: Used for scaling/normalization and as the pool to sample from

### 3. `epsilon` (Exploration probability)
- **Purpose**: Controls the balance between exploration and exploitation
- **Why**: Enables ε-annealing strategy (start with exploration, shift to exploitation)

### 4. `num_samples` (Batch size)
- **Purpose**: Number of experiments to select
- **Why**: Allows batch acquisition with diversity (max-min strategy)

### 5. `random_state` (Random seed)
- **Purpose**: Ensures reproducibility
- **Why**: Important for debugging and fair comparisons

## Sampling method: Novelty + Annealing ε-Greedy Exploration

Our approach combines a novelty-based search for exploitation with an ε-annealing strategy for exploration to ensure both comprehensive coverage and efficient refinement.

- **Search Space**: The search space is a full grid representing all possible experimental conditions. It is generated by taking the Cartesian product of the discrete values for each independent variable. This grid serves as the fixed candidate pool from which all new experiments are selected.

- **Novelty Score & Max-Min Selection (Exploitation)**: When exploiting, we select candidates that are most novel. The process is as follows:
    1.  **Novelty Score**: For each untested candidate point in the search space, we calculate its novelty by measuring the minimum distance to any previously tested point.
    2.  **Max-Min Selection**: We greedily select the candidate with the highest novelty score (i.e., the one furthest from any explored point). This process is repeated, with each new selection maximizing the minimum distance to the set of both previously tested points and the points already chosen in the current selection batch. This encourages diverse, space-filling selections.

- **ε-Annealing Exploration**: To balance exploration and exploitation, we use an annealing (gradually decreasing) value for ε (epsilon). The probability of choosing a random experiment is determined by:
    `epsilon = max(0.05, 0.3 * (1 - step / max_steps))`
    - At the beginning of the experiment (low `step`), ε is high, leading to more random exploration to broadly cover the search space.
    - As the experiment progresses, ε decreases, shifting the focus toward exploitation using our novelty-based selection.

## Key Innovations

We have introduced two main improvements to the standard novelty search.

### 1. RSN: Random Subset Novelty

Instead of applying the greedy max-min selection to the entire pool of candidates (which can be slow and over-emphasize edges), our exploitation branch first samples a small, random window of candidates from the pool. The novelty selection logic is then applied only *within that window*. 

**Benefit**: This approach, which we call Random Subset Novelty (RSN), preserves the robustness of random sampling while retaining the diversity-seeking benefits of novelty search, making the process faster and more representative.

### 2. Stratified Exploration + RSN

To further improve coverage, our exploration is not purely random. Instead, it is **stratified**—randomly selecting from bins (regions) of the search space that are currently under-covered. For exploitation, we extend this by first drawing a *weighted* subset of candidates (favoring under-covered regions) and then applying the RSN logic.

**Benefit**: This ensures the experimentalist fills the search space more uniformly during exploration and continues to prioritize less-tested regions during exploitation.
